{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJvB_EkF_tnN"
   },
   "source": [
    "### Design a housing price predictor taking only floor area (plot size), number of bedrooms, and number of bathrooms into considerations. Out of total 546 data , you may take 70% for designing the predictor and 30% for validating the design. The predictor design should be done using the following methods\n",
    "### c) Design Predictor using Batch Gradient Descent Algorithm, Stochastic Gradient Algorithm and mini batch Gradient Descent algorithms (determining minibatch size is your choice- here it could be 10, 20, 30 etc.) with and without regularization and compare their performances in terms of % error in prediction\n",
    "### d) Implement the LWR algorithm on the Housing Price data set with different tau values. Find out the tau value which will provide the best fit predictor and hence compare its results with a) , b) and c) above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpA2u45FEPfI"
   },
   "source": [
    "### Note: Some Variables are reused so it is suggested to restart the notebook first and then run the notebook in one go from top to down to avoid any error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEhNaGDk_ax5"
   },
   "source": [
    "# Q6c Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "9MniTMj9_-8_",
    "outputId": "e2d6b226-19b9-4115-e592-3baf3f1daec8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrms</th>\n",
       "      <th>stories</th>\n",
       "      <th>driveway</th>\n",
       "      <th>recroom</th>\n",
       "      <th>fullbase</th>\n",
       "      <th>gashw</th>\n",
       "      <th>airco</th>\n",
       "      <th>garagepl</th>\n",
       "      <th>prefarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>5850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49500.0</td>\n",
       "      <td>3060</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60500.0</td>\n",
       "      <td>6650</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000.0</td>\n",
       "      <td>6360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>91500.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>94000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>103000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  lotsize  bedrooms  bathrms  ...  gashw airco garagepl prefarea\n",
       "0     42000.0     5850         3        1  ...     no    no        1       no\n",
       "1     38500.0     4000         2        1  ...     no    no        0       no\n",
       "2     49500.0     3060         3        1  ...     no    no        0       no\n",
       "3     60500.0     6650         3        1  ...     no    no        0       no\n",
       "4     61000.0     6360         2        1  ...     no    no        0       no\n",
       "..        ...      ...       ...      ...  ...    ...   ...      ...      ...\n",
       "541   91500.0     4800         3        2  ...     no   yes        0       no\n",
       "542   94000.0     6000         3        2  ...     no   yes        0       no\n",
       "543  103000.0     6000         3        2  ...     no   yes        1       no\n",
       "544  105000.0     6000         3        2  ...     no   yes        1       no\n",
       "545  105000.0     6000         3        1  ...     no   yes        1       no\n",
       "\n",
       "[546 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whole Assignment will be done using numpy only \n",
    "import numpy as np\n",
    "\n",
    "# pandas is only used to read the csv file since there is no function that allows us to read string data in numpy\n",
    "import pandas as pd\n",
    "\n",
    "#Reading data using pandas\n",
    "url=\"https://raw.githubusercontent.com/Aditya-2001/ML-Assignments-Semester-5/master/Housing%20Price%20data%20set.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5vjMYb6MBlza"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we will convert the pandas columns into numpy array because we are not allowed to use any other library.\n",
    "Note: We will take only those columns into consideration on which we are asked to do prediction.\n",
    "To convert them into numpy array, \n",
    "first we will take series object using data[column name] \n",
    "and then convert it into list using list() function \n",
    "and then finally we will create the numpy array.'''\n",
    "\n",
    "# Feature Columns\n",
    "PlotSize = np.array(list(data[\"lotsize\"]))\n",
    "Bedrooms = np.array(list(data[\"bedrooms\"]))\n",
    "Bathrooms = np.array(list(data[\"bathrms\"]))\n",
    "\n",
    "#Target Column\n",
    "Price = np.array(list(data[\"price\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT-mbAe0BvVS"
   },
   "source": [
    "Approch for preciding in Batch GDA, Stochastic GDA and Mini Batch GDA is similar since in Batch GDA, we take all the samples available for training, whereas in Stochastic GDA, only 1 random sample is taken and in Mini Batch GDA, a random set of batch( like 10 or 20 or 40 or 100 and so on..) is taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kK-pImgBxcU"
   },
   "source": [
    "### Now we will not write separate functions for all. Instead we will be writing a single function that take sample size as input and will give the output W. \n",
    "#### 1. For Batch GDA, Sample Size will be 100% (i.e. all samples)\n",
    "#### 2. For Stochastic GDA, Sample Size will be 1\n",
    "#### 3. For Mini Batch GDA, Sample Size will be s (where s will be predefined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvevP5IzBxfp"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI7QJY6PBxig"
   },
   "source": [
    "Now we have to create the 3 predictors using GDA without regularization.\n",
    "For that we will create a function that will take feature as well as target columns as input as well as the sample_size and returns the predictor using GDA alogirthm.\n",
    "The function will also take the alpha (learning rate) as input.\n",
    "While calling this function we will take care that the data we pass is training data and later we also have to test our data for which we will write a separate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ta-6_nlCA3w"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. X will be the numpy array of feature columns and Y will be target column\n",
    "2. In this function we need to W to optimize it further so, we will use normal equation for that.\n",
    "    And for that we have normal equation function from previous part A.\n",
    "'''\n",
    "\n",
    "def GDA(X, Y, learning_rate, sample_size, W):\n",
    "    '''\n",
    "        We have our previous W\n",
    "        For GDA we have \n",
    "        new W = current W - (learning_rate/sample_size)*(∑ ((h(X)-Y).X*) ), note: ∑ is for sample_size\n",
    "        Here, current W will be an numpy array and similarly X* will also be a numpy array\n",
    "    For that we will simply iterate over X and add 1 over each row\n",
    "    '''\n",
    "    \n",
    "    #Added 1 in each row as done in Normal Equation function\n",
    "    X1=[]\n",
    "    for i in range(len(X)):\n",
    "        X1.append(list(np.insert(X[i],0,1)))\n",
    "    X=np.array(X1)\n",
    "    \n",
    "    #Will pick s random samples from np array\n",
    "    total_index=list(range(10))\n",
    "    sample_index=[]\n",
    "    for i in range(10):\n",
    "        sample_index.append(np.random.choice(total_index))\n",
    "        total_index.remove(sample_index[-1])\n",
    "    \n",
    "    #Calculating (∑ ((h(X)-Y).X*) ) and storing it into value and will be used later on\n",
    "    value=np.zeros((len(W)),dtype=int)\n",
    "    for i in range(len(sample_index)):\n",
    "        current_index=sample_index[i]\n",
    "        predicted_value=0\n",
    "        for j in range(len(W)):\n",
    "            predicted_value+=W[j]*X[current_index][j]\n",
    "        original_value=Y[current_index]\n",
    "        result=np.multiply(X[current_index],(predicted_value-original_value))\n",
    "        value=np.add(value,result)\n",
    "    \n",
    "    #We will now overwrite value from (∑ ((h(X)-Y).X*) ) to (∑ ((h(X)-Y).X*) ) * (learning_rate/sample_size)\n",
    "    value=np.multiply(value,learning_rate/sample_size,dtype=float)\n",
    "                                   \n",
    "    #Finally we have to subtract W and value np matrixes and return W as result\n",
    "    W=np.subtract(W,value)                        \n",
    "    return W\n",
    "\n",
    "def LRNormalEquation(X, Y):\n",
    "    X1=[]\n",
    "    for i in range(len(X)):\n",
    "        X1.append(list(np.insert(X[i],0,1)))\n",
    "    X=np.array(X1)\n",
    "    result1=np.dot(X.transpose(),X)\n",
    "    result1=np.linalg.inv(result1)\n",
    "    result2=np.dot(X.transpose(),Y)\n",
    "    result=np.dot(result1,result2)\n",
    "    return result\n",
    "\n",
    "'''To call the function first we have to merge the numpy arrays into 1\n",
    "So this function merges cells so that data for each index becomes as row for that part only'''\n",
    "def mergeCells(cell):\n",
    "    n=len(cell[0])\n",
    "    m=len(cell)\n",
    "    result=np.ones((n,m),dtype=int)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            result[i][j]=cell[j][i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rmsER8peCEXf"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we have to divide our data into testing and trainging where test size will be 30%.\n",
    "For that we will take first 70% for training and rest for testing\n",
    "We also have to predict data for which we can use the same predict function used in part A/\n",
    "'''\n",
    "train_size=int(0.7*len(PlotSize))\n",
    "train_X=mergeCells([PlotSize[:train_size], Bedrooms[:train_size], Bathrooms[:train_size]])\n",
    "test_X=mergeCells([PlotSize[train_size:], Bedrooms[train_size:], Bathrooms[train_size:]])\n",
    "train_Y=Price[:train_size]\n",
    "test_Y=Price[train_size:]\n",
    "\n",
    "def predict(X,Y,W):\n",
    "    error=0\n",
    "    for i in range(len(Y)):\n",
    "        predicted=abs(W[0] + W[1]*X[i][0] + W[2]*X[i][1] + W[3]*X[i][2])\n",
    "        actual=abs(Y[i])\n",
    "        error+=abs(actual-predicted)/actual\n",
    "    error=error/len(Y)\n",
    "    error=error*100\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ExqIz7GqCKiW"
   },
   "outputs": [],
   "source": [
    "#Now we have to predict for testing data. The below predict function will take testing data and W and return the mean squared error.\n",
    "#Defining epochs and learning rate for 3 algorithms\n",
    "epochs=1000\n",
    "learning_rate=0.0000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZY1mLkkCTRl"
   },
   "source": [
    "#### Batch Gradient Descent Algorithm without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp6x52KmCVf-",
    "outputId": "70d4ace3-46db-4cdc-a926-3b7e996dd6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using Batch GDA without regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Batch GDA without regularization is 18.6745878332%"
     ]
    }
   ],
   "source": [
    "W=LRNormalEquation(train_X,train_Y)\n",
    "for i in range(epochs):\n",
    "    W=GDA(train_X,train_Y,learning_rate,len(train_Y),W)\n",
    "print(\"Model using Batch GDA without regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Batch GDA without regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYS-ia_mCXT1"
   },
   "source": [
    "#### Stochastic Gradient Descent Algorithm without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDnss0x8CaMK",
    "outputId": "006c32b5-8e28-4df2-c6a3-8560ba492c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using Stochastic GDA without regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA without regularization is 18.8001486202%"
     ]
    }
   ],
   "source": [
    "W=LRNormalEquation(train_X,train_Y)\n",
    "for i in range(epochs):\n",
    "    W=GDA(train_X,train_Y,learning_rate,1,W)\n",
    "print(\"Model using Stochastic GDA without regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA without regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7ijpei9Ce--"
   },
   "source": [
    "#### Mini Batch Gradient Descent Algorithm without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9esA5XYCfII",
    "outputId": "de7a6526-7d93-4e73-ee01-58b8b75f2563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using Mini Batch GDA without regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA without regularization is 18.7169049039%"
     ]
    }
   ],
   "source": [
    "batch_size=50\n",
    "W=LRNormalEquation(train_X,train_Y)\n",
    "for each in range(epochs):\n",
    "    W=GDA(train_X,train_Y,learning_rate,batch_size,W)\n",
    "print(\"Model using Mini Batch GDA without regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA without regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJxOHdvoB77H"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "C5DHnK1DBr0O"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we have to create the 3 predictors using GDA with regularization.\n",
    "We have GDA without regularization and for regularization we will add an addition term of alpha*λ/m.\n",
    "'''\n",
    "def GDA_with_Regularization(X, Y, learning_rate, sample_size, W, λ):\n",
    "    '''\n",
    "        We have our previous W\n",
    "        For GDA with regularization we have \n",
    "        new W = current W * (1-alpha*λ/m) - (learning_rate/sample_size)*(∑ ((h(X)-Y).X*) ), note: ∑ is for sample_size\n",
    "        Here, current W will be an numpy array and similarly X* will also be a numpy array\n",
    "    For that we will simply iterate over X and add 1 over each row\n",
    "    '''\n",
    "    \n",
    "    #Added 1 in each row as done in Normal Equation function\n",
    "    X1=[]\n",
    "    for i in range(len(X)):\n",
    "        X1.append(list(np.insert(X[i],0,1)))\n",
    "    X=np.array(X1)\n",
    "    \n",
    "    #Will pick s random samples from np array\n",
    "    total_index=list(range(10))\n",
    "    sample_index=[]\n",
    "    for i in range(10):\n",
    "        sample_index.append(np.random.choice(total_index))\n",
    "        total_index.remove(sample_index[-1])\n",
    "    \n",
    "    #Calculating (∑ ((h(X)-Y).X*) ) and storing it into value and will be used later on\n",
    "    value=np.zeros((len(W)),dtype=int)\n",
    "    for i in range(len(sample_index)):\n",
    "        current_index=sample_index[i]\n",
    "        predicted_value=0\n",
    "        for j in range(len(W)):\n",
    "            predicted_value+=W[j]*X[current_index][j]\n",
    "        original_value=Y[current_index]\n",
    "        result=np.multiply(X[current_index],(predicted_value-original_value))\n",
    "        value=np.add(value,result)\n",
    "    \n",
    "    #We will now overwrite value from (∑ ((h(X)-Y).X*) ) to (∑ ((h(X)-Y).X*) ) * (learning_rate/sample_size)\n",
    "    value=np.multiply(value,learning_rate/sample_size,dtype=float)\n",
    "     \n",
    "    #We will now change W into W * (1-alpha*λ/m)\n",
    "    flag=1-float((learning_rate*λ)/sample_size)\n",
    "    W=np.multiply(W,flag)\n",
    "        \n",
    "    #Finally we have to subtract W and value np matrixes and return W as result\n",
    "    W=np.subtract(W,value)                        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Oszq5PhYCxJe"
   },
   "outputs": [],
   "source": [
    "#Defining lamda/regulizer that will be passed in GDA function\n",
    "λ1=-1000\n",
    "λ2=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5FV_a5RC0gj"
   },
   "source": [
    "#### Batch Gradient Descent Algorithm with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J83nh868C0p9",
    "outputId": "ff578bfe-6294-4839-b12b-cfa052daddba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE-1: λ is -1000\n",
      "Model using Batch GDA with regularization is given below\n",
      "-4894.92 + 5.92 * PlotSize + 5528.57 * Bedrooms + 19010.02 * Bathrooms\n",
      "% error in the model on testing data using Batch GDA with regularization is 18.6745826331%\n",
      "\n",
      "CASE-2: λ is +1000\n",
      "Model using Batch GDA with regularization is given below\n",
      "-4894.92 + 5.92 * PlotSize + 5528.57 * Bedrooms + 19010.02 * Bathrooms\n",
      "% error in the model on testing data using Batch GDA with regularization is 18.6821784209%"
     ]
    }
   ],
   "source": [
    "W=LRNormalEquation(train_X,train_Y)\n",
    "\n",
    "print(\"CASE-1: λ is -1000\")\n",
    "for i in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,len(train_Y),W,λ1)\n",
    "print(\"Model using Batch GDA with regularization is given below\")\n",
    "print(round(W[0],2),\"+\",round(W[1],2),\"* PlotSize +\",round(W[2],2),\"* Bedrooms +\",round(W[3],2),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Batch GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")\n",
    "\n",
    "print(\"\\n\\nCASE-2: λ is +1000\")\n",
    "for i in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,len(train_Y),W,λ2)\n",
    "print(\"Model using Batch GDA with regularization is given below\")\n",
    "print(round(W[0],2),\"+\",round(W[1],2),\"* PlotSize +\",round(W[2],2),\"* Bedrooms +\",round(W[3],2),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Batch GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC7jedCdC0z0"
   },
   "source": [
    "#### Stochastic Gradient Descent Algorithm with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkcFUVcIC068",
    "outputId": "144e2f50-365e-4bfb-9dd1-ce62b5a3eae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE-1: λ is -1000\n",
      "Model using Stochastic GDA with regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19012 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA with regularization is 18.7996525631%\n",
      "\n",
      "CASE-2: λ is +1000\n",
      "Model using Stochastic GDA with regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA with regularization is 18.8002212587%"
     ]
    }
   ],
   "source": [
    "W=LRNormalEquation(train_X,train_Y)\n",
    "\n",
    "print(\"CASE-1: λ is -1000\")\n",
    "for i in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,1,W,λ1)\n",
    "print(\"Model using Stochastic GDA with regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")\n",
    "\n",
    "print(\"\\n\\nCASE-2: λ is +1000\")\n",
    "for i in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,1,W,λ2)\n",
    "print(\"Model using Stochastic GDA with regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ_kj8HeC1EK"
   },
   "source": [
    "#### Mini Batch Gradient Descent Algorithm with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUUUZL9qC1KE",
    "outputId": "18a90cda-e712-405f-ec58-0131281a4db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE-1: λ is -1000\n",
      "Model using Mini Batch GDA with regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA with regularization is 18.7168707596%\n",
      "\n",
      "CASE-2: λ is +1000\n",
      "Model using Mini Batch GDA with regularization is given below\n",
      "-4895 + 6 * PlotSize + 5529 * Bedrooms + 19010 * Bathrooms\n",
      "% error in the model on testing data using Stochastic GDA with regularization is 18.7476596132%"
     ]
    }
   ],
   "source": [
    "batch_size=50\n",
    "W=LRNormalEquation(train_X,train_Y)\n",
    "\n",
    "print(\"CASE-1: λ is -1000\")\n",
    "for each in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,batch_size,W,λ1)\n",
    "print(\"Model using Mini Batch GDA with regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")\n",
    "\n",
    "print(\"\\n\\nCASE-2: λ is +1000\")\n",
    "for each in range(epochs):\n",
    "    W=GDA_with_Regularization(train_X,train_Y,learning_rate,batch_size,W,λ2)\n",
    "print(\"Model using Mini Batch GDA with regularization is given below\")\n",
    "print(round(W[0]),\"+\",round(W[1]),\"* PlotSize +\",round(W[2]),\"* Bedrooms +\",round(W[3]),\"* Bathrooms\")\n",
    "print(\"% error in the model on testing data using Stochastic GDA with regularization is\",end=\" \")\n",
    "print(round(predict(test_X,test_Y,W),10),end=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCrn67y2DL3P"
   },
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUwWEFR6DQ2t"
   },
   "source": [
    "### Result: % error is less when Regularization is done\n",
    "\n",
    "##### The arrangement becomes:\n",
    "\n",
    "## % error : GDA with Regularization < GDA without Regularization\n",
    "\n",
    "# Maximum Error : 18.8001486202%\n",
    "# Minimum Error : 18.6745826331%\n",
    "\n",
    "\n",
    "#### Note: I have taken learning_rate=0.0000000001, epochs=1000, as λ -1000 and +1000 and batch_size as 50 for minibatch GDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYfspozXDoys"
   },
   "source": [
    "# Q6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "BValPbTHDp5E",
    "outputId": "fe3b3510-3761-465b-8084-463db532a707"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrms</th>\n",
       "      <th>stories</th>\n",
       "      <th>driveway</th>\n",
       "      <th>recroom</th>\n",
       "      <th>fullbase</th>\n",
       "      <th>gashw</th>\n",
       "      <th>airco</th>\n",
       "      <th>garagepl</th>\n",
       "      <th>prefarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>5850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49500.0</td>\n",
       "      <td>3060</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60500.0</td>\n",
       "      <td>6650</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000.0</td>\n",
       "      <td>6360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>91500.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>94000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>103000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  lotsize  bedrooms  bathrms  ...  gashw airco garagepl prefarea\n",
       "0     42000.0     5850         3        1  ...     no    no        1       no\n",
       "1     38500.0     4000         2        1  ...     no    no        0       no\n",
       "2     49500.0     3060         3        1  ...     no    no        0       no\n",
       "3     60500.0     6650         3        1  ...     no    no        0       no\n",
       "4     61000.0     6360         2        1  ...     no    no        0       no\n",
       "..        ...      ...       ...      ...  ...    ...   ...      ...      ...\n",
       "541   91500.0     4800         3        2  ...     no   yes        0       no\n",
       "542   94000.0     6000         3        2  ...     no   yes        0       no\n",
       "543  103000.0     6000         3        2  ...     no   yes        1       no\n",
       "544  105000.0     6000         3        2  ...     no   yes        1       no\n",
       "545  105000.0     6000         3        1  ...     no   yes        1       no\n",
       "\n",
       "[546 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whole Assignment will be done using numpy only \n",
    "import numpy as np\n",
    "\n",
    "# pandas is only used to read the csv file since there is no function that allows us to read string data in numpy\n",
    "import pandas as pd\n",
    "\n",
    "#Reading data using pandas\n",
    "url=\"https://raw.githubusercontent.com/Aditya-2001/ML-Assignments-Semester-5/master/Housing%20Price%20data%20set.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_i4tZlQ2DsjS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we will convert the pandas columns into numpy array because we are not allowed to use any other library.\n",
    "Note: We will take only those columns into consideration on which we are asked to do prediction.\n",
    "To convert them into numpy array, \n",
    "first we will take series object using data[column name] \n",
    "and then convert it into list using list() function \n",
    "and then finally we will create the numpy array.'''\n",
    "\n",
    "# Feature Columns\n",
    "PlotSize = np.array(list(data[\"lotsize\"]))\n",
    "Bedrooms = np.array(list(data[\"bedrooms\"]))\n",
    "Bathrooms = np.array(list(data[\"bathrms\"]))\n",
    "\n",
    "#Target Column\n",
    "Price = np.array(list(data[\"price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W6Meg7Y3D5UF"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes X and Y columns as input where\n",
    "X are the values in feature columns and Y is the value in \n",
    "target column. It applies locally weighted regression and \n",
    "predicts the value acc to the algorithm\n",
    "'''\n",
    "def LocallyWeightedLR(X, Y, Tau):\n",
    "    prediction=[]\n",
    "    \n",
    "    #Added 1 in each row as done in Normal Equation function\n",
    "    X1=[]\n",
    "    for i in range(len(X)):\n",
    "        X1.append(list(np.insert(X[i],0,1)))\n",
    "    X=np.array(X1)\n",
    "\n",
    "    #Appying the LWR algorithm for each sample to obtain the predicted value\n",
    "    #And finally adding the value into the prediction list\n",
    "    for i in range(X.shape[0]):\n",
    "        xi=X[i]\n",
    "        X_T=np.transpose(X)\n",
    "        W=kernel(X, xi, Tau)\n",
    "        X_T_W=X_T * W\n",
    "        X_T_WX=np.matmul(X_T_W, X)\n",
    "        InverseX_T_WX=np.linalg.pinv(X_T_WX)\n",
    "        X_T_WXXTW=np.matmul(InverseX_T_WX, X_T_W)\n",
    "        X_T_WXXTWY=np.matmul(X_T_WXXTW, Y)\n",
    "        X_T_WXXTWYT=np.transpose(X_T_WXXTWY)\n",
    "        prediction.append(X_T_WXXTWYT.dot(xi))\n",
    "    return prediction\n",
    "\n",
    "def kernel(X, xi, Tau):\n",
    "    return np.exp(-np.sum((xi - X) ** 2, axis = 1) / (2 * Tau * Tau))\n",
    "\n",
    "'''To call the function first we have to merge the numpy arrays into 1\n",
    "So this function merges cells so that data for each index becomes as row for that part only'''\n",
    "def mergeCells(cell):\n",
    "    n=len(cell[0])\n",
    "    m=len(cell)\n",
    "    result=np.ones((n,m),dtype=int)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            result[i][j]=cell[j][i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vf5_zXfjD6m5"
   },
   "outputs": [],
   "source": [
    "#Taking all the target columns as X\n",
    "X=mergeCells([PlotSize[:], Bedrooms[:], Bathrooms[:]])\n",
    "\n",
    "#Taking all the values of price column for Y\n",
    "Y=Price[:]\n",
    "\n",
    "#This function takes Y and Y predicted and calculates error\n",
    "def predict(Y, Y_prediction):\n",
    "    error=0\n",
    "    for i in range(len(Y)):\n",
    "        error+=abs((Y[i]-Y_prediction[i])/Y[i])\n",
    "    error=error/len(Y)\n",
    "    error=error*100\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3o6WzR0D7l1",
    "outputId": "0cf34680-99d2-4c0d-dc47-1305615aeb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are initial 10 value using LWR\n",
      "Original Value\t\tPredicted Value\n",
      "42000.0 \t\t 42000.0\n",
      "38500.0 \t\t 46333.33333333335\n",
      "49500.0 \t\t 49500.00000000003\n",
      "60500.0 \t\t 60499.999999999985\n",
      "61000.0 \t\t 61966.666666666664\n",
      "66000.0 \t\t 67499.99999999999\n",
      "66000.0 \t\t 66000.0\n",
      "69000.0 \t\t 67499.99999999999\n",
      "83800.0 \t\t 83399.99999999996\n",
      "88500.0 \t\t 82999.99999999997\n",
      "After performing LWR Algorithm the % error when tau = 0.01 is 5.41%"
     ]
    }
   ],
   "source": [
    "#Let's assume tau as given value and predict for it\n",
    "tau=0.01\n",
    "predictionLWR=LocallyWeightedLR(X,Y,tau)\n",
    "print(\"Below are initial 10 value using LWR\\nOriginal Value\\t\\tPredicted Value\")\n",
    "for i in range(10):\n",
    "    print(Y[i],\"\\t\\t\",predictionLWR[i])\n",
    "print(\"After performing LWR Algorithm the % error when tau =\",tau,\"is\",round(predict(Y, predictionLWR),2),end=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIAlGA9pD8q5",
    "outputId": "4491c754-ebc1-420a-d959-24f3031e3dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tau\t\t% Error\n",
      "0.01\t\t5.4073055366\n",
      "0.02\t\t5.4073055366\n",
      "0.03\t\t5.4073055366\n",
      "0.04\t\t5.4073055366\n",
      "0.05\t\t5.4073055366\n",
      "0.06\t\t5.4073055366\n",
      "0.07\t\t5.4073055366\n",
      "0.08\t\t5.4073055366\n",
      "0.09\t\t5.4073055366\n",
      "0.1\t\t5.4073055366\n",
      "0.11\t\t5.4073055366\n",
      "0.12\t\t5.4073055366\n",
      "0.13\t\t5.4073055366\n",
      "0.14\t\t5.4073055367\n",
      "0.15\t\t5.407305539\n",
      "0.16\t\t5.4073055785\n",
      "0.17\t\t5.4073059139\n",
      "0.18\t\t5.4073058008\n",
      "0.19\t\t5.4073066095\n",
      "0.2\t\t5.407309645\n",
      "0.21\t\t5.4073186611\n",
      "0.22\t\t5.4073414849\n",
      "0.23\t\t5.407392172\n",
      "0.24\t\t5.4074927324\n",
      "0.25\t\t5.4076749731\n",
      "0.26\t\t5.4079808234\n",
      "0.27\t\t5.4084611374\n",
      "0.28\t\t5.409173895\n",
      "0.29\t\t5.410181229\n",
      "0.3\t\t5.4115459215\n",
      "0.31\t\t5.413327913\n",
      "0.32\t\t5.4155808926\n",
      "0.33\t\t5.4183494088\n",
      "0.34\t\t5.4216669112\n",
      "0.35\t\t5.4255545161\n",
      "0.36\t\t5.4300201298\n",
      "0.37\t\t5.435059262\n",
      "0.38\t\t5.4406555379\n",
      "0.39\t\t5.4467822096\n",
      "0.4\t\t5.4534040641\n",
      "0.41\t\t5.4604793443\n",
      "0.42\t\t5.4682072568\n",
      "0.43\t\t5.4763114554\n",
      "0.44\t\t5.484734308\n",
      "0.45\t\t5.4934263462\n",
      "0.46\t\t5.5023408545\n",
      "0.47\t\t5.5114354394\n",
      "0.48\t\t5.5206723165\n",
      "0.49\t\t5.5300193053\n",
      "0.5\t\t5.5394501438\n",
      "0.51\t\t5.5488804049\n",
      "0.52\t\t5.5585456043\n",
      "0.53\t\t5.5683928852\n",
      "0.54\t\t5.5782668421\n",
      "0.55\t\t5.5881643087\n",
      "0.56\t\t5.5983436177\n",
      "0.57\t\t5.6084596915\n",
      "0.58\t\t5.618876394\n",
      "0.59\t\t5.6293339353\n",
      "0.6\t\t5.6398362935\n",
      "0.61\t\t5.6503873291\n",
      "0.62\t\t5.6606535508\n",
      "0.63\t\t5.6713005789\n",
      "0.64\t\t5.6820043214\n",
      "0.65\t\t5.6930157002\n",
      "0.66\t\t5.7045441665\n",
      "0.67\t\t5.7161902559\n",
      "0.68\t\t5.7278762814\n",
      "0.69\t\t5.7395977227\n",
      "0.7\t\t5.7513491401\n",
      "0.71\t\t5.7631241331\n",
      "0.72\t\t5.7749157665\n",
      "0.73\t\t5.7867163812\n",
      "0.74\t\t5.7985179227\n",
      "0.75\t\t5.81031194\n",
      "0.76\t\t5.8220897849\n",
      "0.77\t\t5.8310087408\n",
      "0.78\t\t5.8364602958\n",
      "0.79\t\t5.8475458417\n",
      "0.8\t\t5.8585585535\n",
      "0.81\t\t5.8694892544\n",
      "0.82\t\t5.8803309163\n",
      "0.83\t\t5.8910771241\n",
      "0.84\t\t5.9021811093\n",
      "0.85\t\t5.9132002381\n",
      "0.86\t\t5.9241220304\n",
      "0.87\t\t5.9349381141\n",
      "0.88\t\t5.9456442045\n",
      "0.89\t\t5.9562333727\n",
      "0.9\t\t5.966701986\n",
      "0.91\t\t5.9770452325\n",
      "0.92\t\t5.9874358285\n",
      "0.93\t\t5.9977469001\n",
      "0.94\t\t6.0079208464\n",
      "0.95\t\t6.0179562568\n",
      "0.96\t\t6.0278507426\n",
      "0.97\t\t6.0376027211\n",
      "0.98\t\t6.047211277\n",
      "0.99\t\t6.0566877695\n"
     ]
    }
   ],
   "source": [
    "# % Error for different tau values \n",
    "print(\"Tau\\t\\t% Error\")\n",
    "max_iteration=100\n",
    "req_values=[]\n",
    "for i in range(1,max_iteration):\n",
    "    req_values.append(i/100)\n",
    "for tau in req_values:\n",
    "    predictionLWR=LocallyWeightedLR(X,Y,tau)\n",
    "    print(tau,end=\"\\t\\t\")\n",
    "    print(round(predict(Y, predictionLWR),10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFXNAr7KEBzx"
   },
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihgQaEqkEDTJ"
   },
   "source": [
    "### Result: % error is less when using LWR Algorithm.\n",
    "\n",
    "#### In comparison to (a), (b) and (c) parts, my observation is that the minimum error is in LWR Algorithm."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IIT2019210_Q6c and Q6d Submission Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
